---
title: "Extra Object Project Experiment"
author: "Sarah"
date: "27/07/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

For batches 1-8, the stimuli were selected randomly 
For batches 9-16, the stimuli were selected using the software.


# Load in Data

```{r load packages}

rm(list = ls()) #run this line to clear your environment
library(lme4); library(lmerTest); library(tidyverse); library(data.table); library(dtplyr); library(effsize); library(pwr); library(Rmisc); library(car)

data_dir = "~/Desktop/ObjectProject/extra experiment/data/"



```

```{r load data and save CSV filename to a new column}
relevantData = list.files(path = data_dir, full.names = TRUE)

data = data.table()
for (i in relevantData) {
  df_temp = setDT(read.csv(i))
  df_temp[, filename := i]
  data = rbind(data, df_temp)
}

data = setDT(data)

```

```{r new columns to denote condition and batch}

data$group = NULL #remove group col

#identify batches 
data[grep(pattern = "extraexperiment_1_", x = filename, ), batch := 1 ]
data[grep(pattern = "extraexperiment_2_", x = filename, ), batch := 2 ]
data[grep(pattern = "extraexperiment_3_", x = filename, ), batch := 3 ]
data[grep(pattern = "extraexperiment_4_", x = filename, ), batch := 4 ]
data[grep(pattern = "extraexperiment_5_", x = filename, ), batch := 5 ]
data[grep(pattern = "extraexperiment_6_", x = filename, ), batch := 6 ]
data[grep(pattern = "extraexperiment_7_", x = filename, ), batch := 7 ]
data[grep(pattern = "extraexperiment_8_", x = filename, ), batch := 8 ]
data[grep(pattern = "extraexperiment_9_", x = filename, ), batch := 9 ]
data[grep(pattern = "extraexperiment_10_", x = filename, ), batch := 10 ]
data[grep(pattern = "extraexperiment_11_", x = filename, ), batch := 11 ]
data[grep(pattern = "extraexperiment_12_", x = filename, ), batch := 12 ]
data[grep(pattern = "extraexperiment_13_", x = filename, ), batch := 13 ]
data[grep(pattern = "extraexperiment_14_", x = filename, ), batch := 14 ]
data[grep(pattern = "extraexperiment_15_", x = filename, ), batch := 15 ]
data[grep(pattern = "extraexperiment_16_", x = filename, ), batch := 16 ]

to_assign_ids = data[, .N, keyby = .(subject, batch)] 
to_assign_ids[, participant := 1:.N] #add new participant column
to_assign_ids$N = NULL

data = left_join(data, to_assign_ids)

data = data %>% arrange(participant) %>% select(participant, everything()) # arrange by participant

# remove unnecessary columns

data$filename = NULL

# rename key presses for retrieval phase to be interpretable
data[blockcode == "retrieval" & response == "36", response := "old"]
data[blockcode == "retrieval" & response == "37", response := "new"]


```

Maybe remove participants who were bad with data cleaning

# analyse retrieval

```{r view RT latency distribution}

hist(data[blockcode == "retrieval" & latency < 3000]$latency, breaks = 50) #cutoff around 300ms

HR_by_condition = data[latency %between% c(300,1999) & blockcode == "retrieval", .(mean = mean(correct)), by = .(old_object_condition)]

```

```{r try removing participants I said were bad}

#data_clean = data[!batch %in% c(1,7)]
#view(data_clean[batch == 3 & subject %in% c(5,15)]) #participant 6 and 16
#view(data_clean[batch == 8 & subject %in% c(4,8)]) # participant 5 and 10
#data_clean = data_clean[!participant %in% c(5,6,10,16)]

#HR_by_condition_clean = data_clean[latency %between% c(300,1999) & blockcode == "retrieval", .(mean = mean(correct)), by = .(old_object_condition, participant)]
#unique(HR_by_condition_clean$participant)

```

# data cleaning 
```{r remove abnormal trial latencies}

retrieval = data[blockcode == "retrieval" & latency %between% c(300,1999)]

exclude_incomplete_retrieval = retrieval[, .N, by = .(participant)][N < 160]$participant #more than half their trials were of abnormal latency or they didn't finish

retrieval = retrieval[!participant %in% c(exclude_incomplete_retrieval)]

```

# calculate effect size for all stimuli
```{r effect size}

random = retrieval[batch %in% c(1:8)]
software = retrieval[batch %in% c(9:16)]

unique(random$participant) #38
unique(software$participant) #40

allparticipants <- unique(data$participant)
retrievalparticipants <-unique(retrieval$participant)


cohendfrandom <- random[, .(mean =mean(correct)), by = .(participant, old_object_condition)]
cohendfsoftware <- software[, .(mean =mean(correct)), by = .(participant, old_object_condition)]

cohen.d(cohendfrandom[old_object_condition == 3]$mean, cohendfrandom[old_object_condition == 1]$mean, paired = T)

cohen.d(cohendfsoftware[old_object_condition == 3]$mean, cohendfsoftware[old_object_condition == 1]$mean, paired = T)

```

## stats for all stimuli
```{r stats for all stimuli}

#Anova where you look at random vs. Software and 1 vs 3 stimulus presentations to see if the interaction is significant
stats_df = retrieval[batch %in% c(1:8), image_type := "Random"][batch %in% c(9:16), image_type := "Software"][old_object_condition %in% c(1,3)]

aov.1 <- aov(correct ~image_type * old_object_condition, data = stats_df)
summary(aov.1)
model.tables(aov.1, type = "means", se = TRUE)
TukeyHSD(aov.1, which = "old_object_condition")


```


# power analysis

```{r power analysis}

# power analysis for random
pwr.t.test(d = .437, sig.level = .05, power = .8, type = ("paired"))
# n is 43


# power analysis for software
pwr.t.test(d = .525, sig.level = .05, power = .8, type = ("paired"))
# n is 30

#this means using the software results in 30% less participants needed to achieve the same power
#(43-30)/43

```

# analyse what happens when only a few stimuli are used (10 per condition)

```{r segment out first 10 stimuli}

snip_9_10 = c("A0.jpg","A1.jpg","A2.jpg","A3.jpg","A4.jpg","A5.jpg","A6.jpg","A7.jpg","A8.jpg","A9.jpg","B0.jpg","B1.jpg","B2.jpg","B3.jpg","B4.jpg","B5.jpg","B6.jpg","B7.jpg","B8.jpg","B9.jpg")
snip_11_12 = c("C0.jpg","C1.jpg","C2.jpg","C3.jpg","C4.jpg","C5.jpg","C6.jpg","C7.jpg","C8.jpg","C9.jpg","D0.jpg","D1.jpg","D2.jpg","D3.jpg","D4.jpg","D5.jpg","D6.jpg","D7.jpg","D8.jpg","D9.jpg")
snip_13_14 = c("E0.jpg","E1.jpg","E2.jpg","E3.jpg","E4.jpg","E5.jpg","E6.jpg","E7.jpg","E8.jpg","E9.jpg","F0.jpg","F1.jpg","F2.jpg","F3.jpg","F4.jpg","F5.jpg","F6.jpg","F7.jpg","F8.jpg","F9.jpg")
snip_15_16 = c("G0.jpg","G1.jpg","G2.jpg","G3.jpg","G4.jpg","G5.jpg","G6.jpg","G7.jpg","G8.jpg","G9.jpg","H0.jpg","H1.jpg","H2.jpg","H3.jpg","H4.jpg","H5.jpg","H6.jpg","H7.jpg","H8.jpg","H9.jpg")


software_snippet = software[
  (batch %in% c(9,10) & stimulus %in% snip_9_10) | 
    (batch %in% c(11,12) & stimulus %in% snip_11_12) |
    (batch %in% c(13,14) & stimulus %in% snip_13_14) |
    (batch %in% c(15,16) & stimulus %in% snip_15_16)]

software_snippet_with_new = software[
  (batch %in% c(9,10) & stimulus %in% c(snip_9_10,snip_11_12)) | 
    (batch %in% c(11,12) & stimulus %in% c(snip_11_12,snip_9_10)) |
    (batch %in% c(13,14) & stimulus %in% c(snip_13_14,snip_15_16)) |
    (batch %in% c(15,16) & stimulus %in% c(snip_15_16,snip_13_14))]

snip_1_2 = c("Blanket.jpg", "Candy_Chocolate.jpg", "Cake_Wedding.jpg", "Helmet_Construction.jpg","SculptureMetalFish.jpg", "Notebook.jpg", "GasBurner.jpg", "Guitar_Acoustic.jpg", "Toy_BlocksPlastic Colourful.jpg", "TinChristmas.jpg", "Tickets_Blank.jpg",
"Desk_School.jpg", "LeatherPuncherTool.jpg", "Toy_StackingRing.jpg", "Drink_Green.jpg", "Bullet.jpg", "Ashtray_Empty.jpg", "NeedlesAcupuncture.jpg","Beater_Electric.jpg", "Generator.jpg")
snip_3_4 = c("TurkeyDinner.jpg", "Broom_Long.jpg", "Ball_8.jpg", "SkullDeer.jpg", "Shield_Antique.jpg",
"Pajamas.jpg", "Radio_Vintage.jpg","BicycleGear.jpg","Ball_Disco.jpg","Pig.jpg","CookieCutter_Tree.jpg", "Tire_Hollow.jpg", "Lamp_TableWhite.jpg", "LampPost_OneBulb.jpg", "Glass_Martini.jpg","Currants.jpg","SkiPoles.jpg", "CrepeMaker.jpg", "Switch_LightWhite.jpg","Paddle_Beach.jpg")
snip_5_6 = c("Makeup_Compact.jpg", "Ladybug.jpg", "Corkboard.jpg", "Hedgehog.jpg", "Walker_Blue.jpg", "Nuts_Pecan.jpg", "Branch.jpg", "Cannon.jpg", "ManholeCover.jpg","Bowl_Glass.jpg","CoffeeLid.jpg", "Heelpad.jpg","Can_Oblong.jpg","Briefcase_Silver.jpg","Glass_Beer.jpg","Carousel.jpg","Case_Pencil.jpg","TailLight.jpg","IceCream_Popsicle.jpg","Earring_Hoop.jpg")
snip_7_8 = c("WaterCooler.jpg","Ostrich.jpg","ShoeLace_Flat.jpg","Blueberry.jpg","Sphinx.jpg", "Bucket_WoodenLight.jpg","WaterHeater.jpg","Walkman.jpg","Toy_DonkeyFur.jpg","Case_CD.jpg","FuzzyDice.jpg","Bagpipes.jpg","GrillRack.jpg","Stick_IceHockey.jpg","Lips_Wax.jpg","Dice.jpg","Snorkle.jpg","Glasses_Sun.jpg","Toy_Rooster.jpg","Suit_Women.jpg")

random_snippet = random[
  (batch %in% c(1,2) & stimulus %in% snip_1_2) | 
    (batch %in% c(3,4) & stimulus %in% snip_3_4) |
    (batch %in% c(5,6) & stimulus %in% snip_5_6) |
    (batch %in% c(7,8) & stimulus %in% snip_7_8)]

```


```{r segmented effect size}

cohendfrandomsnip <- random_snippet[, .(mean =mean(correct)), by = .(participant, old_object_condition)]

cohen.d(cohendfrandomsnip[old_object_condition == 3]$mean, cohendfrandomsnip[old_object_condition == 1]$mean, paired = T) #.569

#calculate mean by participant and condition
cohendfsoftwaresnip <- software_snippet_with_new[, .(mean =mean(correct)), by = .(participant, old_object_condition)]

cohen.d(cohendfsoftwaresnip[old_object_condition == 3]$mean, cohendfsoftwaresnip[old_object_condition == 1]$mean, paired = T) #1.4

```

```{r segmented power analysis}

# power analysis for random
pwr.t.test(d = .52, sig.level = .05, power = .8, type = ("paired"))
# n is 31


# power analysis for software
pwr.t.test(d = .7, sig.level = .05, power = .8, type = ("paired"))
# n is 18

#this means using the software results in 30% less participants needed to achieve the same power at smaller level of stimuli
#(26-18)/26

```

# loop through 10 randomly selected stimuli (or 50)

## calculate effect size using hit rate

```{r loop through random stimuli}

#load condition files

list_1 <- read.csv("list_1.csv", header = FALSE)
list_2 <- read.csv("list_2.csv", header = FALSE)
list_3 <- read.csv("list_3.csv", header = FALSE)
list_4 <- read.csv("list_4.csv", header = FALSE)
list_5 <- read.csv("list_5.csv", header = FALSE)
list_6 <- read.csv("list_6.csv", header = FALSE)
list_7 <- read.csv("list_7.csv", header = FALSE)
list_8 <- read.csv("list_8.csv", header = FALSE)


#select 10 random stimuli for each of 

effect_sizes <- c()

n = 10

for (i in 1:100) {
  sample_1 = sample_n(list_1, n)
  sample_2 = sample_n(list_2, n)
  sample_3 = sample_n(list_3, n)
  sample_4 = sample_n(list_4, n)
  sample_5 = sample_n(list_5, n)
  sample_6 = sample_n(list_6, n)
  sample_7 = sample_n(list_7, n)
  sample_8 = sample_n(list_8, n)
  
  
  snippet = random[
  (batch %in% c(1,2) & stimulus %in% sample_1$V1 | stimulus %in% sample_2$V1) | 
    (batch %in% c(3,4) & stimulus %in% sample_3$V1 | stimulus %in% sample_4$V1) |
    (batch %in% c(5,6) & stimulus %in% sample_5$V1 | stimulus %in% sample_6$V1) |
    (batch %in% c(7,8) & stimulus %in% sample_7$V1 | stimulus %in% sample_8$V1)]
  
  
  meansnippet = snippet[, .(mean =mean(correct)), by = .(participant, old_object_condition)]
  
  goodparticipants = meansnippet[, .N, by=participant]
  goodparticipants = goodparticipants[goodparticipants$N == 3,]$participant #if they don't have a value for all three conditions, a paired samples effect size wont work
  meansnippet = meansnippet[meansnippet$participant %in% goodparticipants,]
  
  ef = cohen.d(meansnippet[old_object_condition == 3]$mean, meansnippet[old_object_condition == 1]$mean, paired = T)
  effect_sizes <- c(effect_sizes, ef$estimate)
}
return(effect_sizes)

mean(effect_sizes)

HR_effect_sizes <-effect_sizes

hist(HR_effect_sizes)

#calculate p value (percentage of effect sizes above the softwares 1.417)

pvalue_HR = length(effect_sizes[effect_sizes > 1.417])/100

```


## use corrected hit rate

```{r corrected HR}
#calculate corrected hit rate

random[, HR := mean(correct), by = participant]
random[, avg_mem := correct - HR, by = participant]

effect_sizes <- c()

n = 10

for (i in 1:100) {
  sample_1 = sample_n(list_1, n)
  sample_2 = sample_n(list_2, n)
  sample_3 = sample_n(list_3, n)
  sample_4 = sample_n(list_4, n)
  sample_5 = sample_n(list_5, n)
  sample_6 = sample_n(list_6, n)
  sample_7 = sample_n(list_7, n)
  sample_8 = sample_n(list_8, n)
  
  
  snippet = random[
  (batch %in% c(1,2) & stimulus %in% sample_1$V1 | stimulus %in% sample_2$V1) | 
    (batch %in% c(3,4) & stimulus %in% sample_3$V1 | stimulus %in% sample_4$V1) |
    (batch %in% c(5,6) & stimulus %in% sample_5$V1 | stimulus %in% sample_6$V1) |
    (batch %in% c(7,8) & stimulus %in% sample_7$V1 | stimulus %in% sample_8$V1)]
  
  
  meansnippet = snippet[, .(mean =mean(avg_mem)), by = .(participant, old_object_condition)]
  
  goodparticipants = meansnippet[, .N, by=participant]
  goodparticipants = goodparticipants[goodparticipants$N == 3,]$participant #if they don't have a value for all three conditions, a paired samples effect size wont work
  meansnippet = meansnippet[meansnippet$participant %in% goodparticipants,]
  
  ef = cohen.d(meansnippet[old_object_condition == 3]$mean, meansnippet[old_object_condition == 1]$mean, paired = T)
  effect_sizes <- c(effect_sizes, ef$estimate)
}
return(effect_sizes)

mean(effect_sizes) 

corrected_HR_effect_sizes <- effect_sizes
hist(corrected_HR_effect_sizes) 



#do corrected HR with software

software[, HR := mean(correct), by = participant]
software[, avg_mem := correct - HR, by = participant]

software_snippet = software[
  (batch %in% c(9,10) & stimulus %in% snip_9_10) | 
    (batch %in% c(11,12) & stimulus %in% snip_11_12) |
    (batch %in% c(13,14) & stimulus %in% snip_13_14) |
    (batch %in% c(15,16) & stimulus %in% snip_15_16)]


cohendfsoftwaresnip <- software_snippet[, .(mean =mean(avg_mem)), by = .(participant, old_object_condition)]

cohen.d(cohendfsoftwaresnip[old_object_condition == 3]$mean, cohendfsoftwaresnip[old_object_condition == 1]$mean, paired = T) #1.72

#calculate p value (percentage of effect sizes above the softwares 1.72)

pvalue_HR_corrected = length(corrected_HR_effect_sizes[corrected_HR_effect_sizes > 1.72])/100


```


## use dprime

```{r calculate dprime as well as HR}

effect_sizes <- c()

n = 10

for (i in 1:100) {
  sample_1 = sample_n(list_1, n)
  sample_2 = sample_n(list_2, n)
  sample_3 = sample_n(list_3, n)
  sample_4 = sample_n(list_4, n)
  sample_5 = sample_n(list_5, n)
  sample_6 = sample_n(list_6, n)
  sample_7 = sample_n(list_7, n)
  sample_8 = sample_n(list_8, n)
  
  
  snippet = random[
  ((batch %in% c(1,2,3,4)) & (stimulus %in% sample_1$V1 | stimulus %in% sample_2$V1 | stimulus %in% sample_3$V1 | stimulus %in% sample_4$V1)) | 
    ((batch %in% c(5,6,7,8)) & (stimulus %in% sample_5$V1 | stimulus %in% sample_6$V1 | stimulus %in% sample_7$V1 | stimulus %in% sample_8$V1))] #this takes only the stimuli that were seen for each batch
  
  
  stats_by_participant = dcast(snippet,
                           value.var = "correct",
                           participant ~ old_object_condition,
                           fill=0,
                           mean, na.rm=T)
  stats_by_participant$V1 = NULL
  names(stats_by_participant)[2:4] = c("FA", "HR_1", "HR_3") # rename to be more descriptive
  stats_by_participant[, FA := 1-FA] # make FA column actually correspond to FA
  stats_by_participant[FA==0, FA := 1/80][FA==1, FA := 1-(1/80)] # correct 0s and 1s
  stats_by_participant[HR_1==0, HR_1 := 1/80][HR_1==1, HR_1 := 1-(1/80)]
  stats_by_participant[HR_3==0, HR_3 := 1/80][HR_3==1, HR_3 := 1-(1/80)]
  stats_by_participant[, dprime_1 := qnorm(HR_1) - qnorm(FA)]
  stats_by_participant[, dprime_3 := qnorm(HR_3) - qnorm(FA)]
  
  #snippet = merge(snippet, stats_by_participant, by="participant")
 
  ef = cohen.d(stats_by_participant$dprime_3, stats_by_participant$dprime_1, paired = T)
  effect_sizes <- c(effect_sizes, ef$estimate)
}
return(effect_sizes)

mean(effect_sizes)

dprime_effect_sizes <- effect_sizes

hist(dprime_effect_sizes)




# software with dprime

stats_by_participant = dcast(software_snippet_with_new,
                           value.var = "correct",
                           participant ~ old_object_condition,
                           fill=0,
                           mean, na.rm=T)
  
stats_by_participant$V1 = NULL
names(stats_by_participant)[2:4] = c("FA", "HR_1", "HR_3") # rename to be more descriptive
  stats_by_participant[, FA := 1-FA] # make FA column actually correspond to FA
  stats_by_participant[FA==0, FA := 1/80][FA==1, FA := 1-(1/80)] # correct 0s and 1s
  stats_by_participant[HR_1==0, HR_1 := 1/80][HR_1==1, HR_1 := 1-(1/80)]
  stats_by_participant[HR_3==0, HR_3 := 1/80][HR_3==1, HR_3 := 1-(1/80)]
  stats_by_participant[, dprime_1 := qnorm(HR_1) - qnorm(FA)]
  stats_by_participant[, dprime_3 := qnorm(HR_3) - qnorm(FA)]

ef = cohen.d(stats_by_participant$dprime_3, stats_by_participant$dprime_1, paired = T) #0.791

#calculate p value (percentage of effect sizes above the softwares 0.791)

pvalue_dprime = length(dprime_effect_sizes[dprime_effect_sizes > 0.791])/100

```

# do same analysis with 50 stimuli per condition using the software

## hit rate, software, 50 stim

```{r get 50 stimuli per condition - software, HR}

#load condition files

list_9 <- read.csv("list_9.csv", header = FALSE)
list_10 <- read.csv("list_10.csv", header = FALSE)
list_11 <- read.csv("list_11.csv", header = FALSE)
list_12 <- read.csv("list_12.csv", header = FALSE)
list_13 <- read.csv("list_13.csv", header = FALSE)
list_14 <- read.csv("list_14.csv", header = FALSE)
list_15 <- read.csv("list_15.csv", header = FALSE)
list_16 <- read.csv("list_16.csv", header = FALSE)

#select first 50 stimuli

effect_sizes <- c()

n = 50 # can change this to get other stimuli per condition

  sample_9 = list_9[1:n,]
  sample_10 = list_10[1:n,]
  sample_11 = list_11[1:n,]
  sample_12 = list_12[1:n,]
  sample_13 = list_13[1:n,]
  sample_14 = list_14[1:n,]
  sample_15 = list_15[1:n,]
  sample_16 = list_16[1:n,]
  
  
  snippet = software[
  (batch %in% c(9,10) & stimulus %in% sample_9 | stimulus %in% sample_10) | 
    (batch %in% c(11,12) & stimulus %in% sample_11 | stimulus %in% sample_12) |
    (batch %in% c(13,14) & stimulus %in% sample_13 | stimulus %in% sample_14) |
    (batch %in% c(15,16) & stimulus %in% sample_15 | stimulus %in% sample_16)]
  
  meansnippet = snippet[, .(mean =mean(correct)), by = .(participant, old_object_condition)]

  ef = cohen.d(meansnippet[old_object_condition == 3]$mean, meansnippet[old_object_condition == 1]$mean, paired = T)

HR_effect_size_software_50stim <-ef


```

## corrected hit rate, software, 50 stim
```{r software, 50 stim per condition, corrected HR}

#first 50 stimuli sampled in chunk above

  meansnippet = snippet[, .(mean =mean(avg_mem)), by = .(participant, old_object_condition)]

  ef = cohen.d(meansnippet[old_object_condition == 3]$mean, meansnippet[old_object_condition == 1]$mean, paired = T)

HR_corrected_effect_size_software_50stim <-ef

```


## dprime, software, 50 stim

```{r software, 50 stim per condition, dprime}

  stats_by_participant = dcast(snippet,
                           value.var = "correct",
                           participant ~ old_object_condition,
                           fill=0,
                           mean, na.rm=T)
  stats_by_participant$V1 = NULL
  names(stats_by_participant)[2:4] = c("FA", "HR_1", "HR_3") # rename to be more descriptive
  stats_by_participant[, FA := 1-FA] # make FA column actually correspond to FA
  stats_by_participant[FA==0, FA := 1/80][FA==1, FA := 1-(1/80)] # correct 0s and 1s
  stats_by_participant[HR_1==0, HR_1 := 1/80][HR_1==1, HR_1 := 1-(1/80)]
  stats_by_participant[HR_3==0, HR_3 := 1/80][HR_3==1, HR_3 := 1-(1/80)]
  stats_by_participant[, dprime_1 := qnorm(HR_1) - qnorm(FA)]
  stats_by_participant[, dprime_3 := qnorm(HR_3) - qnorm(FA)]
 
  ef = cohen.d(stats_by_participant$dprime_3, stats_by_participant$dprime_1, paired = T)
  
dprime_effect_size_software_50stim <-ef

```

# Create table for change in effect size gain as stimuli per condition increases

```{r create table}

plot_ef <- data.frame(matrix(ncol = 5, nrow = 32))
colnames(plot_ef) <- c("stimpergroup","mean","group","CI_upper","CI_lower")
plot_ef$stimpergroup <- rep(seq(5,80,5), each=2)
plot_ef$group <- rep(c("Random","Software"))

random_ef_fun<- function(n){

effect_sizes <- c()

for (i in 1:1000) {
  sample_1 = sample_n(list_1, n)
  sample_2 = sample_n(list_2, n)
  sample_3 = sample_n(list_3, n)
  sample_4 = sample_n(list_4, n)
  sample_5 = sample_n(list_5, n)
  sample_6 = sample_n(list_6, n)
  sample_7 = sample_n(list_7, n)
  sample_8 = sample_n(list_8, n)
  
  
  snippet = random[
  (batch %in% c(1,2) & stimulus %in% sample_1$V1 | stimulus %in% sample_2$V1) | 
    (batch %in% c(3,4) & stimulus %in% sample_3$V1 | stimulus %in% sample_4$V1) |
    (batch %in% c(5,6) & stimulus %in% sample_5$V1 | stimulus %in% sample_6$V1) |
    (batch %in% c(7,8) & stimulus %in% sample_7$V1 | stimulus %in% sample_8$V1)]
  
  
  meansnippet = snippet[, .(mean =mean(correct)), by = .(participant, old_object_condition)]
  
  goodparticipants = meansnippet[, .N, by=participant]
  goodparticipants = goodparticipants[goodparticipants$N == 3,]$participant #if they don't have a value for all three conditions, a paired samples effect size wont work
  meansnippet = meansnippet[meansnippet$participant %in% goodparticipants,]
  
  ef = cohen.d(meansnippet[old_object_condition == 3]$mean, meansnippet[old_object_condition == 1]$mean, paired = T)
  effect_sizes <- c(effect_sizes, ef$estimate)
}

return(effect_sizes)
}

# fill data table with results from the function

rand_5 = random_ef_fun(5)
sum_rand5 <- CI(rand_5)
plot_ef[1,2] <- sum_rand5[2]
plot_ef[1,4] <- sum_rand5[1]
plot_ef[1,5] <- sum_rand5[3]

rand_10 = random_ef_fun(10)
sum_rand10 <- CI(rand_10)
plot_ef[3,2] <- sum_rand10[2]
plot_ef[3,4] <- sum_rand10[1]
plot_ef[3,5] <- sum_rand10[3]

rand_15 = random_ef_fun(15)
sum_rand15 <- CI(rand_15)
plot_ef[5,2] <- sum_rand15[2]
plot_ef[5,4] <- sum_rand15[1]
plot_ef[5,5] <- sum_rand15[3]

rand_20 = random_ef_fun(20)
sum_rand20 <- CI(rand_20)
plot_ef[7,2] <- sum_rand20[2]
plot_ef[7,4] <- sum_rand20[1]
plot_ef[7,5] <- sum_rand20[3]

rand_25 = random_ef_fun(25)
sum_rand25 <- CI(rand_25)
plot_ef[9,2] <- sum_rand25[2]
plot_ef[9,4] <- sum_rand25[1]
plot_ef[9,5] <- sum_rand25[3]

rand_30 = random_ef_fun(30)
sum_rand30 <- CI(rand_30)
plot_ef[11,2] <- sum_rand30[2]
plot_ef[11,4] <- sum_rand30[1]
plot_ef[11,5] <- sum_rand30[3]

rand_35 = random_ef_fun(35)
sum_rand35 <- CI(rand_35)
plot_ef[13,2] <- sum_rand35[2]
plot_ef[13,4] <- sum_rand35[1]
plot_ef[13,5] <- sum_rand35[3]

rand_40 = random_ef_fun(40)
sum_rand40 <- CI(rand_40)
plot_ef[15,2] <- sum_rand40[2]
plot_ef[15,4] <- sum_rand40[1]
plot_ef[15,5] <- sum_rand40[3]

rand_45 = random_ef_fun(45)
sum_rand45 <- CI(rand_45)
plot_ef[17,2] <- sum_rand45[2]
plot_ef[17,4] <- sum_rand45[1]
plot_ef[17,5] <- sum_rand45[3]

rand_50 = random_ef_fun(50)
sum_rand50 <- CI(rand_50)
plot_ef[19,2] <- sum_rand50[2]
plot_ef[19,4] <- sum_rand50[1]
plot_ef[19,5] <- sum_rand50[3]

rand_55 = random_ef_fun(55)
sum_rand55 <- CI(rand_55)
plot_ef[21,2] <- sum_rand55[2]
plot_ef[21,4] <- sum_rand55[1]
plot_ef[21,5] <- sum_rand55[3]

rand_60 = random_ef_fun(60)
sum_rand60 <- CI(rand_60)
plot_ef[23,2] <- sum_rand60[2]
plot_ef[23,4] <- sum_rand60[1]
plot_ef[23,5] <- sum_rand60[3]

rand_65 = random_ef_fun(65)
sum_rand65 <- CI(rand_65)
plot_ef[25,2] <- sum_rand65[2]
plot_ef[25,4] <- sum_rand65[1]
plot_ef[25,5] <- sum_rand65[3]

rand_70 = random_ef_fun(70)
sum_rand70 <- CI(rand_70)
plot_ef[27,2] <- sum_rand70[2]
plot_ef[27,4] <- sum_rand70[1]
plot_ef[27,5] <- sum_rand70[3]

rand_75 = random_ef_fun(75)
sum_rand75 <- CI(rand_75)
plot_ef[29,2] <- sum_rand75[2]
plot_ef[29,4] <- sum_rand75[1]
plot_ef[29,5] <- sum_rand75[3]

rand_80 = random_ef_fun(80)
sum_rand80 <- CI(rand_80)
plot_ef[31,2] <- sum_rand80[2]
plot_ef[31,4] <- sum_rand80[1]
plot_ef[31,5] <- sum_rand80[3]

### software
software_ef_fun <- function(n){
effect_sizes <- c()

  sample_9 = list_9[1:n,]
  sample_10 = list_10[1:n,]
  sample_11 = list_11[1:n,]
  sample_12 = list_12[1:n,]
  sample_13 = list_13[1:n,]
  sample_14 = list_14[1:n,]
  sample_15 = list_15[1:n,]
  sample_16 = list_16[1:n,]
  
  
  snippet = software[
  (batch %in% c(9,10) & stimulus %in% sample_9 | stimulus %in% sample_10) | 
    (batch %in% c(11,12) & stimulus %in% sample_11 | stimulus %in% sample_12) |
    (batch %in% c(13,14) & stimulus %in% sample_13 | stimulus %in% sample_14) |
    (batch %in% c(15,16) & stimulus %in% sample_15 | stimulus %in% sample_16)]
  
  meansnippet = snippet[, .(mean =mean(correct)), by = .(participant, old_object_condition)]

  ef = cohen.d(meansnippet[old_object_condition == 3]$mean, meansnippet[old_object_condition == 1]$mean, paired = T)
  
  effect_size = ef$estimate
  
  return(effect_size)
}

soft_5 = software_ef_fun(5)
plot_ef[2,2] <- mean(soft_5)

soft_10 = software_ef_fun(10)
plot_ef[4,2] <- mean(soft_10)

soft_15 = software_ef_fun(15)
plot_ef[6,2] <- mean(soft_15)

soft_20 = software_ef_fun(20)
plot_ef[8,2] <- mean(soft_20)

soft_25 = software_ef_fun(25)
plot_ef[10,2] <- mean(soft_25)

soft_30 = software_ef_fun(30)
plot_ef[12,2] <- mean(soft_30)

soft_35 = software_ef_fun(35)
plot_ef[14,2] <- mean(soft_35)

soft_40 = software_ef_fun(40)
plot_ef[16,2] <- mean(soft_40)

soft_45 = software_ef_fun(45)
plot_ef[18,2] <- mean(soft_45)

soft_50 = software_ef_fun(50)
plot_ef[20,2] <- mean(soft_50)

soft_55 = software_ef_fun(55)
plot_ef[22,2] <- mean(soft_55)

soft_60 = software_ef_fun(60)
plot_ef[24,2] <- mean(soft_60)

soft_65 = software_ef_fun(65)
plot_ef[26,2] <- mean(soft_65)

soft_70 = software_ef_fun(70)
plot_ef[28,2] <- mean(soft_70)

soft_75= software_ef_fun(75)
plot_ef[30,2] <- mean(soft_75)

soft_80= software_ef_fun(80)
plot_ef[32,2] <- mean(soft_80)

```

```{r plot effect sizes}

ef_graph <- ggplot(plot_ef, aes(x = stimpergroup, y = mean, color = group)) +
  geom_line() +
  ylab("effect size") +
  geom_errorbar(aes(ymin=CI_lower, ymax=CI_upper), width = .7)

ggsave(ef_graph, file = "effectsizes.png")
```

Are these effect sizes significantly different?
```{r stats on effect sizes}

setDT(plot_ef)
t.test(plot_ef[group == "Random" &stimpergroup == 5]$mean,plot_ef[group == "Software" & stimpergroup ==5]$mean)

# power analysis for random
pwr.t.test(d = plot_ef[group == "Random" & stimpergroup == 10]$mean, sig.level = .05, power = .8, type = ("paired"))
# n is 13


# power analysis for software
pwr.t.test(d = plot_ef[group == "Software" & stimpergroup ==10]$mean, sig.level = .05, power = .8, type = ("paired"))
#n is 6


```

#is the software actually equating memorability in these groups, and is random not equating memorability
Sanity check

```{r import memorability values}

app_values = read.csv("full_dt_pf.csv")

app_values = select(app_values, stimulus, memorability)



```

```{r run through simulations and collect average memorability at each level of stim per condition}

### Random

mem_differences <- data.frame(matrix(ncol = 3, nrow =0))
colnames(mem_differences) <- c("diff","n","i")

for (n in seq(5,80,5)){
  
    
  for (i in 1:1000) {
    
    sample_1 = sample_n(list_1, n)
    sample_2 = sample_n(list_2, n)
    sample_3 = sample_n(list_3, n)
    sample_4 = sample_n(list_4, n)
    sample_5 = sample_n(list_5, n)
    sample_6 = sample_n(list_6, n)
    sample_7 = sample_n(list_7, n)
    sample_8 = sample_n(list_8, n)
    
  snippet = random[
  (batch %in% c(1,2) & stimulus %in% sample_1$V1 | stimulus %in% sample_2$V1) | 
    (batch %in% c(3,4) & stimulus %in% sample_3$V1 | stimulus %in% sample_4$V1) |
    (batch %in% c(5,6) & stimulus %in% sample_5$V1 | stimulus %in% sample_6$V1) |
    (batch %in% c(7,8) & stimulus %in% sample_7$V1 | stimulus %in% sample_8$V1)]
  
  snippet = left_join(snippet, app_values)
  
  mean_mem = snippet[, .(mean =mean(memorability)), by = .(old_object_condition)]
  
  difference = data.frame(matrix(ncol = 3, nrow = 1))
  colnames(difference) <- c("diff","n","i")
  difference$diff = abs(mean_mem[old_object_condition == 1]$mean - mean_mem[old_object_condition == 3]$mean)
  
  difference$n = n
  difference$i = i
  mem_differences = rbind(mem_differences, difference)
  
  }

}

mem_differences


### software

app_values_soft = read.csv("experiment_stimuli/summary.csv")

app_values_soft$newname = str_split(app_values_soft$newname, "/")
app_values_soft$stimulus = sapply(app_values_soft$newname, "[[", 2)

app_values_soft = select(app_values_soft, stimulus, memorability)


mem_differences_soft <- data.frame(matrix(ncol = 2, nrow =0))
colnames(mem_differences_soft) <- c("diff","n")

for (n in seq(5,80,5)){

  sample_9 = list_9[1:n,]
  sample_10 = list_10[1:n,]
  sample_11 = list_11[1:n,]
  sample_12 = list_12[1:n,]
  sample_13 = list_13[1:n,]
  sample_14 = list_14[1:n,]
  sample_15 = list_15[1:n,]
  sample_16 = list_16[1:n,]
  
  
  snippet = software[
  (batch %in% c(9,10) & stimulus %in% sample_9 | stimulus %in% sample_10) | 
    (batch %in% c(11,12) & stimulus %in% sample_11 | stimulus %in% sample_12) |
    (batch %in% c(13,14) & stimulus %in% sample_13 | stimulus %in% sample_14) |
    (batch %in% c(15,16) & stimulus %in% sample_15 | stimulus %in% sample_16)]
  
  snippet = left_join(snippet, app_values_soft)
  
  mean_mem = snippet[, .(mean =mean(memorability)), by = .(old_object_condition)]
  
  difference = data.frame(matrix(ncol = 2, nrow = 1))
  colnames(difference) <- c("diff","n")
  difference$diff = abs(mean_mem[old_object_condition == 1]$mean - mean_mem[old_object_condition == 3]$mean)
  
  difference$n = n
  
  mem_differences_soft = rbind(mem_differences_soft, difference)
}

mem_differences_soft
```

```{r plot difference in memorability}

mem_differences$group = "Random"
setDT(mem_differences)
mem_differences = mem_differences[, .(diff = mean(diff), CI_upper = CI(diff)[[1]], CI_lower= CI(diff)[[3]]), by = .(n, group)]

mem_differences_soft$group = "Software"

plot_mem = rbind(mem_differences, mem_differences_soft, fill = TRUE)


mem_image <- ggplot(plot_mem, aes(x = n, y = diff, color = group)) +
  geom_line() +
  ylab("mean memorability difference") +
  geom_errorbar(aes(ymin=CI_lower, ymax=CI_upper), width = .7) +
  ggtitle("Difference in stimuli memorability between conditions")

ggsave(mem_image, file = "stim_mem_conditions.png")

```


# Look at different batches to see if they play a role in memorability spike?

```{r calculate at 10 stimuli}

#is there a fluke at 10 stimuli per condition? maybe theres one wierd batch?

ef_by_batch = data.frame(matrix(ncol = 3, nrow=0))
colnames(ef_by_batch) = c("n","batch","ef")

for (n in seq(5,80,5)){

  sample_9 = list_9[1:n,]
  sample_10 = list_10[1:n,]
  sample_11 = list_11[1:n,]
  sample_12 = list_12[1:n,]
  sample_13 = list_13[1:n,]
  sample_14 = list_14[1:n,]
  sample_15 = list_15[1:n,]
  sample_16 = list_16[1:n,]
  
  
  snippet = software[
  (batch %in% c(9,10) & stimulus %in% sample_9 | stimulus %in% sample_10) | 
    (batch %in% c(11,12) & stimulus %in% sample_11 | stimulus %in% sample_12) |
    (batch %in% c(13,14) & stimulus %in% sample_13 | stimulus %in% sample_14) |
    (batch %in% c(15,16) & stimulus %in% sample_15 | stimulus %in% sample_16)]
  
  meansnippet = snippet[, .(mean =mean(correct)), by = .(participant, old_object_condition,batch)]
  
  for (b in 9:15){
    ef= cohen.d(meansnippet[old_object_condition == 3 & batch == b]$mean, meansnippet[old_object_condition == 1& batch == b]$mean, paired = T)
    
    ef_df = data.frame(matrix(ncol = 3, nrow=1))
    colnames(ef_df) = c("n","batch","ef")
    
    ef_df$n = n
    ef_df$batch = b
    ef_df$ef = ef$estimate
  
    ef_by_batch = rbind(ef_by_batch, ef_df)
    
  }
}
  

ef_by_batch

ef_by_batch_plot <- ggplot(ef_by_batch, aes(x = n, y = ef, color = as.factor(batch))) +
  geom_point()+
  ylab("ef") 

ggsave(ef_by_batch_plot, file = "ef_by_batch.png")

# looks like most batches just have very high effect sizes (only one that is small) and it's not some fluke driving up the effect sizes

```

